{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VMware Documentation Analysis Experiment\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ë‹¨ì¼ ì¿¼ë¦¬ì— ëŒ€í•œ ëª¨ë¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹¤í–‰í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: /home/remote/jwoo/THU/Capstone\n",
            "ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: /home/remote/jwoo/THU/Capstone/results/experiment_log.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ í™•ì¸\n",
        "project_root = os.getcwd()\n",
        "log_path = os.path.join(project_root, \"results\", \"experiment_log.csv\")\n",
        "\n",
        "print(f\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {project_root}\")\n",
        "print(f\"ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ (PYTHONPATH ì„¤ì • ì™„ë£Œ)...\n",
            "\n",
            "=== Long Context LLM Experiment Runner ===\n",
            "\n",
            "[Experiment] Starting: VMware Documentation\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 11335.96it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 4766.25it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 4027.18it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 3283.21it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|â–         | 3/103 [00:00<00:00, 3233.02it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|â–         | 3/103 [00:00<00:00, 2791.86it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 2933.59it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 2720.04it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 2674.94it/s, Materializing param=embeddings.word_embeddings.weight]      \n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 2522.74it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 2645.14it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 2523.90it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 2571.61it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 2410.52it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 2475.43it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 2391.45it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 2437.60it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 2333.63it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 2400.31it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 2339.01it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 2403.61it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 2308.60it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 2318.26it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 2262.71it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|â–ˆâ–        | 13/103 [00:00<00:00, 2311.70it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|â–ˆâ–        | 13/103 [00:00<00:00, 2246.45it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|â–ˆâ–        | 14/103 [00:00<00:00, 2269.03it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|â–ˆâ–        | 14/103 [00:00<00:00, 2229.23it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 2278.77it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 2239.83it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 2248.35it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 2212.04it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 2111.56it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 2078.99it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 2121.79it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 2093.37it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1898.28it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1876.65it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 1919.72it/s, Materializing param=encoder.layer.0.output.dense.bias]      \n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 1900.11it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 1904.03it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 1885.08it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 1923.87it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 1898.50it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 1828.45it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 1809.92it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  23%|â–ˆâ–ˆâ–       | 24/103 [00:00<00:00, 1844.22it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–       | 24/103 [00:00<00:00, 1828.28it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1858.06it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1842.39it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 1854.72it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 1839.11it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 1863.34it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 1847.14it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 1867.40it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 1852.99it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 1878.09it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 1864.48it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 1766.07it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 1752.98it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 1619.72it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 1607.13it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 1482.23it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 1473.75it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 1494.83it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 1485.36it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–      | 34/103 [00:00<00:00, 1509.89it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–      | 34/103 [00:00<00:00, 1502.64it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 1526.11it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 1518.94it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 1540.70it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 1533.69it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 1557.50it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 1547.78it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 1569.11it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 1562.16it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 1583.45it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 1576.55it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 1586.83it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 1579.70it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 1598.97it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 1591.38it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 1603.17it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 1596.18it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 1499.57it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 1489.53it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/103 [00:00<00:00, 1500.01it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/103 [00:00<00:00, 1494.24it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/103 [00:00<00:00, 1515.70it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/103 [00:00<00:00, 1506.95it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 1523.20it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 1517.68it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 1535.55it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 1530.17it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 1441.04it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 1435.94it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 1452.94it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 1446.22it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 1460.38it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 1455.48it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 1413.35it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 1407.22it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 1422.31it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 1418.01it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 1430.57it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 1426.31it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 1442.71it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 1438.63it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/103 [00:00<00:00, 1448.95it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/103 [00:00<00:00, 1444.66it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 1458.13it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 1453.99it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 1465.92it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 1461.23it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 1472.66it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 1465.93it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 1474.62it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 1469.31it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 1482.92it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 1477.75it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 1489.04it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 1485.00it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1496.34it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1492.35it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1478.99it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1474.71it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1484.83it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1480.89it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/103 [00:00<00:00, 1365.06it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/103 [00:00<00:00, 1361.22it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1370.38it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1367.11it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 1379.17it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 1376.06it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 1368.91it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 1364.04it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 1374.00it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 1370.95it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 1382.72it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 1379.71it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 1389.69it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 1385.86it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 1394.21it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 1391.02it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 1402.08it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 1398.43it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 1409.41it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 1406.51it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/103 [00:00<00:00, 1416.22it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/103 [00:00<00:00, 1413.25it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 1423.14it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 1420.26it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 1428.20it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 1424.96it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 1365.45it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 1362.57it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 1372.41it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 1369.71it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 1378.79it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 1375.43it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 1385.39it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 1382.83it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 1390.07it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 1386.84it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 1396.53it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 1394.00it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 1402.25it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 1399.57it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 85/103 [00:00<00:00, 1382.94it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 85/103 [00:00<00:00, 1380.20it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/103 [00:00<00:00, 1386.80it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/103 [00:00<00:00, 1384.17it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 1393.31it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 1390.79it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 1396.43it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 1393.66it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 1402.55it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 1400.00it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 1404.50it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 1401.98it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 1391.87it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 1389.38it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 1396.80it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 1393.81it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 1367.94it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 1365.57it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 1374.12it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 1371.89it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 1352.61it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 1350.24it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/103 [00:00<00:00, 1358.94it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/103 [00:00<00:00, 1356.80it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 1364.70it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 1362.61it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 1372.22it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 1370.23it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 1379.85it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 1376.62it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 1385.90it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 1383.91it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 1390.65it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 1388.47it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 1394.86it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 1392.89it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1403.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1401.33it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1397.59it/s, Materializing param=pooler.dense.weight]\n",
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "  [Query] Processing: List the differences of the 3q, 3s and 3m release ...\n",
            "[*] Step 1: í…ìŠ¤íŠ¸ ì •ì œ ë° êµ¬ì¡° ë¶„ì„ ì¤‘...\n",
            "[*] ì•Œë¦¼: ë‹¨ì¼ ì„¹ì…˜ ê°ì§€. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ 7ê°œ ë‹¨ìœ„ë¡œ ê°•ì œ ë¶„í• í•©ë‹ˆë‹¤.\n",
            "[*] Step 2: ë³‘ë ¬ ì „ì²˜ë¦¬ ê°€ë™ (ë‹¨ìœ„: 8 ì„¹ì…˜ / Workers: 7)\n",
            "\n",
            "Processing:   0%|          | 0/8 [00:00<?, ?it/s]\n",
            "Processing:  12%|â–ˆâ–        | 1/8 [00:00<00:02,  3.26it/s]\n",
            "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s]\n",
            "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.46it/s]\n",
            "[*] Step 3: ì™„ë£Œ (ìƒì„±ëœ ì²­í¬ ìˆ˜: 4543)\n",
            "[*] ì¸ë² ë”© ìƒì„± ì¤‘: 4543 ì²­í¬ ë¶„ì„...\n",
            "[*] CPU ë©€í‹°í”„ë¡œì„¸ìŠ¤ ê°€ì† ëª¨ë“œ ê°€ë™ (Workers: 7)\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "**1. í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜:**\n",
            "- \"3q release\"\n",
            "- \"3s release\"\n",
            "- \"3m...\n",
            "[*] 42ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/42 [00:00<?, ?it/s]\n",
            "Scouting:   2%|â–         | 1/42 [00:00<00:40,  1.02it/s]\n",
            "Scouting:   5%|â–         | 2/42 [00:01<00:24,  1.61it/s]\n",
            "Scouting:  10%|â–‰         | 4/42 [00:01<00:12,  3.13it/s]\n",
            "Scouting:  17%|â–ˆâ–‹        | 7/42 [00:01<00:05,  6.21it/s]\n",
            "Scouting:  26%|â–ˆâ–ˆâ–Œ       | 11/42 [00:02<00:04,  7.34it/s]\n",
            "Scouting:  33%|â–ˆâ–ˆâ–ˆâ–      | 14/42 [00:02<00:03,  7.54it/s]\n",
            "Scouting:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 15/42 [00:02<00:04,  6.19it/s]\n",
            "Scouting:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 17/42 [00:03<00:03,  7.39it/s]\n",
            "Scouting:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 18/42 [00:03<00:03,  7.63it/s]\n",
            "Scouting:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 20/42 [00:03<00:02,  8.77it/s]\n",
            "Scouting:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 22/42 [00:03<00:02,  9.11it/s]\n",
            "Scouting:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24/42 [00:03<00:02,  7.94it/s]\n",
            "Scouting:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 25/42 [00:04<00:02,  7.38it/s]\n",
            "Scouting:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 26/42 [00:04<00:02,  7.44it/s]\n",
            "Scouting:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 28/42 [00:04<00:02,  6.24it/s]\n",
            "Scouting:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 29/42 [00:05<00:02,  4.51it/s]\n",
            "Scouting:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:05<00:02,  4.60it/s]\n",
            "Scouting:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 32/42 [00:05<00:01,  5.94it/s]\n",
            "Scouting:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 34/42 [00:05<00:01,  6.95it/s]\n",
            "Scouting:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 35/42 [00:05<00:01,  5.99it/s]\n",
            "Scouting:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 37/42 [00:06<00:00,  7.39it/s]\n",
            "Scouting:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 38/42 [00:06<00:00,  5.81it/s]\n",
            "Scouting:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 39/42 [00:06<00:00,  4.79it/s]\n",
            "Scouting:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 40/42 [00:06<00:00,  5.26it/s]\n",
            "Scouting:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 41/42 [00:06<00:00,  5.60it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:07<00:00,  5.09it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:07<00:00,  5.82it/s]\n",
            "  [Query] Processing: List me a timeline for when each version of the Vm...\n",
            "[*] ë¡œì»¬ ìºì‹œ ë°œê²¬: data/cache/vmware_txt_v2.pkl ë¡œë“œ ì¤‘...\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "**1. í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜:**\n",
            "- \"VMware vCenter\"\n",
            "- \"Version relea...\n",
            "[*] 42ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/42 [00:00<?, ?it/s]\n",
            "Scouting:   2%|â–         | 1/42 [00:01<00:45,  1.11s/it]\n",
            "Scouting:  10%|â–‰         | 4/42 [00:01<00:09,  4.14it/s]\n",
            "Scouting:  17%|â–ˆâ–‹        | 7/42 [00:01<00:04,  7.19it/s]\n",
            "Scouting:  21%|â–ˆâ–ˆâ–       | 9/42 [00:01<00:03,  9.11it/s]\n",
            "Scouting:  26%|â–ˆâ–ˆâ–Œ       | 11/42 [00:01<00:03,  9.60it/s]\n",
            "Scouting:  31%|â–ˆâ–ˆâ–ˆ       | 13/42 [00:01<00:03,  8.65it/s]\n",
            "Scouting:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 15/42 [00:02<00:03,  8.85it/s]\n",
            "Scouting:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 17/42 [00:02<00:03,  8.01it/s]\n",
            "Scouting:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 19/42 [00:02<00:03,  7.16it/s]\n",
            "Scouting:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 21/42 [00:02<00:02,  8.69it/s]\n",
            "Scouting:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/42 [00:03<00:01, 10.25it/s]\n",
            "Scouting:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 25/42 [00:03<00:01, 11.31it/s]\n",
            "Scouting:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/42 [00:03<00:01, 11.34it/s]\n",
            "Scouting:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30/42 [00:03<00:00, 13.17it/s]\n",
            "Scouting:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 32/42 [00:03<00:00, 11.01it/s]\n",
            "Scouting:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 34/42 [00:03<00:00, 12.03it/s]\n",
            "Scouting:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 36/42 [00:04<00:01,  5.09it/s]\n",
            "Scouting:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 38/42 [00:05<00:00,  4.33it/s]\n",
            "Scouting:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 40/42 [00:05<00:00,  5.10it/s]\n",
            "Scouting:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 41/42 [00:06<00:00,  4.24it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:06<00:00,  3.87it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:06<00:00,  6.45it/s]\n",
            "\n",
            "[Experiment] Starting: EU AI Act Analysis\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 29959.31it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 6364.65it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 5146.39it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 4054.43it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|â–         | 3/103 [00:00<00:00, 2786.91it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|â–         | 3/103 [00:00<00:00, 1465.69it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 1691.08it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 1144.42it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 879.71it/s, Materializing param=embeddings.word_embeddings.weight]       \n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 774.26it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 794.50it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 744.86it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 831.87it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 820.34it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 892.76it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 744.02it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 628.35it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 623.13it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 676.53it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 637.12it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 681.20it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 658.81it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 697.41it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 686.32it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|â–ˆâ–        | 13/103 [00:00<00:00, 705.01it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|â–ˆâ–        | 13/103 [00:00<00:00, 673.06it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|â–ˆâ–        | 14/103 [00:00<00:00, 714.69it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|â–ˆâ–        | 14/103 [00:00<00:00, 710.62it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 747.95it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 742.53it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 776.26it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 771.64it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 802.67it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 787.64it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 794.77it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 774.36it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 778.72it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 766.30it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 792.37it/s, Materializing param=encoder.layer.0.output.dense.bias]      \n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 750.63it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 773.90it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 770.61it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 797.66it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 723.03it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 680.66it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 677.09it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  23%|â–ˆâ–ˆâ–       | 24/103 [00:00<00:00, 699.27it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–       | 24/103 [00:00<00:00, 690.79it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 704.97it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 702.60it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 721.95it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 710.20it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 722.15it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 709.91it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 730.76it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 728.66it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 750.03it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 747.94it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 763.53it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 749.17it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 758.24it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 742.96it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 742.57it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 732.44it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 727.77it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 720.68it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–      | 34/103 [00:00<00:00, 732.57it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–      | 34/103 [00:00<00:00, 723.22it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 736.07it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 728.09it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 720.84it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 715.17it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 726.72it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 722.94it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 738.15it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 735.86it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 749.20it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 747.71it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 764.08it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 762.69it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 779.03it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 777.67it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 791.31it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 789.65it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 805.37it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 803.94it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/103 [00:00<00:00, 819.75it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/103 [00:00<00:00, 818.26it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/103 [00:00<00:00, 832.70it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/103 [00:00<00:00, 831.27it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 846.94it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 845.57it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 861.16it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 859.70it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 869.24it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 866.79it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 880.26it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 877.89it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 890.95it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 888.56it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 902.39it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 900.08it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 912.02it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 909.65it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 923.19it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 920.89it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 931.37it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 928.78it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/103 [00:00<00:00, 941.32it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/103 [00:00<00:00, 938.90it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 951.80it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 949.39it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 961.20it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 958.82it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 970.56it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 966.70it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 978.74it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 976.28it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 988.69it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 985.75it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 996.75it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 994.19it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1006.36it/s, Materializing param=encoder.layer.3.attention.self.value.bias] \n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1003.66it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1015.15it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1011.85it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1023.69it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1021.11it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/103 [00:00<00:00, 1031.58it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/103 [00:00<00:00, 1028.94it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1040.66it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1037.94it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 1048.36it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 1045.75it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 1057.07it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 1054.70it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 1065.91it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 1062.29it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 1073.29it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 1070.73it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 1081.89it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 1078.50it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 1089.24it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 1086.65it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 1097.56it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 1095.15it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 1103.76it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 1101.16it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/103 [00:00<00:00, 1111.76it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/103 [00:00<00:00, 1109.38it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 1118.50it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 1116.02it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 1126.36it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 1123.20it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 1132.79it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 1129.24it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 1139.37it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 1136.95it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 1145.85it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 1143.09it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 1152.18it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 1150.52it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 1161.72it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 1160.25it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 1169.55it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 1167.97it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 1178.99it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 1177.53it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 85/103 [00:00<00:00, 1188.67it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 85/103 [00:00<00:00, 1187.26it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/103 [00:00<00:00, 1196.94it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/103 [00:00<00:00, 1195.34it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 1206.01it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 1204.50it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 1215.34it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 1213.89it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 1224.73it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 1222.87it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 1233.32it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 1227.58it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 1236.70it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 1234.21it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 1241.74it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 1239.21it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 1248.35it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 1245.85it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 1254.23it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 1251.49it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 1259.40it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 1256.94it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/103 [00:00<00:00, 1265.08it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/103 [00:00<00:00, 1261.67it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 1270.29it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 1267.87it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 1275.73it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 1273.21it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 1282.08it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 1279.59it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 1288.48it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 1285.80it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 1293.44it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 1291.04it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 1299.63it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 1297.33it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1304.74it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1302.25it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1297.08it/s, Materializing param=pooler.dense.weight]\n",
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "  [Query] Processing: How many articles are there in the AI Act?...\n",
            "[*] Step 1: í…ìŠ¤íŠ¸ ì •ì œ ë° êµ¬ì¡° ë¶„ì„ ì¤‘...\n",
            "[*] ì•Œë¦¼: ë‹¨ì¼ ì„¹ì…˜ ê°ì§€. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ 7ê°œ ë‹¨ìœ„ë¡œ ê°•ì œ ë¶„í• í•©ë‹ˆë‹¤.\n",
            "[*] Step 2: ë³‘ë ¬ ì „ì²˜ë¦¬ ê°€ë™ (ë‹¨ìœ„: 7 ì„¹ì…˜ / Workers: 7)\n",
            "\n",
            "Processing:   0%|          | 0/7 [00:00<?, ?it/s]\n",
            "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 286.00it/s]\n",
            "[*] Step 3: ì™„ë£Œ (ìƒì„±ëœ ì²­í¬ ìˆ˜: 20)\n",
            "[*] ì¸ë² ë”© ìƒì„± ì¤‘: 20 ì²­í¬ ë¶„ì„...\n",
            "[*] CPU ë©€í‹°í”„ë¡œì„¸ìŠ¤ ê°€ì† ëª¨ë“œ ê°€ë™ (Workers: 7)\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "1. **í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜**:\n",
            "   - \"AI Act\"\n",
            "   - \"articles in AI ...\n",
            "[*] 20ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "Scouting:   5%|â–Œ         | 1/20 [00:00<00:15,  1.22it/s]\n",
            "Scouting:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  3.66it/s]\n",
            "Scouting:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:02,  6.84it/s]\n",
            "Scouting:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:01,  7.65it/s]\n",
            "Scouting:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:01<00:00, 10.09it/s]\n",
            "Scouting:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:01<00:00,  7.91it/s]\n",
            "Scouting:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:02<00:00,  9.85it/s]\n",
            "Scouting:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:02<00:00,  6.82it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  4.02it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.40it/s]\n",
            "  [Query] Processing: Summarize the requirements for high-risk AI system...\n",
            "[*] ë¡œì»¬ ìºì‹œ ë°œê²¬: data/cache/aiact_txt_v2.pkl ë¡œë“œ ì¤‘...\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "**1. í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜:**\n",
            "- \"high-risk AI systems\"\n",
            "- \"require...\n",
            "[*] 20ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "Scouting:   5%|â–Œ         | 1/20 [00:01<00:19,  1.01s/it]\n",
            "Scouting:  10%|â–ˆ         | 2/20 [00:01<00:08,  2.07it/s]\n",
            "Scouting:  20%|â–ˆâ–ˆ        | 4/20 [00:01<00:03,  4.62it/s]\n",
            "Scouting:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:02<00:05,  2.71it/s]\n",
            "Scouting:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:02<00:04,  3.20it/s]\n",
            "Scouting:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:02<00:03,  3.67it/s]\n",
            "Scouting:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:03,  3.47it/s]\n",
            "Scouting:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:03<00:02,  3.56it/s]\n",
            "Scouting:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:03<00:01,  5.55it/s]\n",
            "Scouting:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  5.28it/s]\n",
            "Scouting:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:04<00:02,  2.69it/s]\n",
            "Scouting:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:04<00:01,  3.20it/s]\n",
            "Scouting:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:05<00:01,  2.83it/s]\n",
            "Scouting:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:05<00:01,  2.76it/s]\n",
            "Scouting:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:05<00:00,  2.86it/s]\n",
            "Scouting:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:06<00:00,  2.98it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:07<00:00,  1.77it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:07<00:00,  2.79it/s]\n",
            "  [Query] Processing: What are the prohibited AI practices according to ...\n",
            "[*] ë¡œì»¬ ìºì‹œ ë°œê²¬: data/cache/aiact_txt_v2.pkl ë¡œë“œ ì¤‘...\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "1. **í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜**:\n",
            "   - \"Article 5\"\n",
            "   - \"prohibited A...\n",
            "[*] 20ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "Scouting:   5%|â–Œ         | 1/20 [00:00<00:16,  1.12it/s]\n",
            "Scouting:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  5.09it/s]\n",
            "Scouting:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:02,  5.58it/s]\n",
            "Scouting:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:01,  7.09it/s]\n",
            "Scouting:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:01<00:01,  8.71it/s]\n",
            "Scouting:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:01<00:00, 10.61it/s]\n",
            "Scouting:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:01<00:00, 14.47it/s]\n",
            "Scouting:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:01<00:00, 14.75it/s]\n",
            "Scouting:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:02<00:00,  5.92it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.85it/s]\n",
            "\n",
            "[Experiment] Starting: EU National Parks File\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 25420.02it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 5047.30it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 4415.06it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 3411.39it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|â–         | 3/103 [00:00<00:00, 2731.26it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|â–         | 3/103 [00:00<00:00, 860.96it/s, Materializing param=embeddings.position_embeddings.weight] \n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 965.71it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 861.12it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 934.56it/s, Materializing param=embeddings.word_embeddings.weight]      \n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 801.30it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 899.23it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 690.52it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 771.88it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 762.13it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 801.07it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 791.58it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 856.16it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 782.54it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 697.88it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 673.58it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 724.45it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 717.85it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 769.62it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 764.14it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|â–ˆâ–        | 13/103 [00:00<00:00, 804.32it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|â–ˆâ–        | 13/103 [00:00<00:00, 781.44it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|â–ˆâ–        | 14/103 [00:00<00:00, 803.44it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|â–ˆâ–        | 14/103 [00:00<00:00, 771.64it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 714.01it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 707.92it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 728.08it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 683.01it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 698.07it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 684.54it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 663.63it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 610.90it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 620.52it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 603.48it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 623.04it/s, Materializing param=encoder.layer.0.output.dense.bias]      \n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 576.42it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 590.03it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 588.04it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 609.47it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 595.46it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 617.22it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 615.36it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  23%|â–ˆâ–ˆâ–       | 24/103 [00:00<00:00, 636.12it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–       | 24/103 [00:00<00:00, 605.65it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 624.38it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 612.51it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 626.88it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 608.72it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 625.81it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 622.78it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 641.81it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 640.25it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 656.97it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 649.76it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 666.93it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 664.58it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 682.26it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 680.00it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 698.03it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 694.78it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 711.87it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 709.51it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–      | 34/103 [00:00<00:00, 727.77it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–      | 34/103 [00:00<00:00, 726.33it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 743.73it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 742.24it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 759.79it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 758.34it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 775.90it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 774.41it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 788.96it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 785.98it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 802.23it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 799.80it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 815.10it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 812.55it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 827.94it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 825.42it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 840.42it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 837.88it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 853.00it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 850.43it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/103 [00:00<00:00, 865.89it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/103 [00:00<00:00, 862.54it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/103 [00:00<00:00, 877.63it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/103 [00:00<00:00, 874.61it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 888.87it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 886.37it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 900.09it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 897.56it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 910.97it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 908.42it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 921.33it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 918.73it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 932.50it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 929.92it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 943.22it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 940.60it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 954.13it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 952.34it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 967.34it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 965.76it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 977.47it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 974.81it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/103 [00:00<00:00, 987.65it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/103 [00:00<00:00, 985.03it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 997.25it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 994.61it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 1007.30it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 1004.63it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 1016.74it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 1015.01it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 1029.17it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 1027.54it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 1041.01it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 1039.33it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 1051.55it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 1049.80it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1063.61it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1062.01it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1075.38it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1073.65it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1087.25it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1080.79it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/103 [00:00<00:00, 1092.89it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/103 [00:00<00:00, 1089.62it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1099.84it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1097.00it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 1109.01it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 1106.35it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 1117.59it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 1113.97it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 1125.71it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 1123.05it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 1134.27it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 1131.52it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 1141.22it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 1138.45it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 1149.89it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 1146.62it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 1156.28it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 1153.48it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 1164.68it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 1162.03it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/103 [00:00<00:00, 1171.36it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/103 [00:00<00:00, 1168.61it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 1179.61it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 1176.98it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 1187.37it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 1183.75it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 1194.40it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 1191.77it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 1202.50it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 1199.29it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 1208.69it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 1206.05it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 1216.68it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 1214.09it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 1222.99it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 1220.30it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 1230.06it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 1227.36it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 1237.11it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 1233.52it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 85/103 [00:00<00:00, 1241.99it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 85/103 [00:00<00:00, 1239.29it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/103 [00:00<00:00, 1249.45it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/103 [00:00<00:00, 1245.20it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 1254.98it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 1252.33it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 1262.24it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 1258.02it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 1268.35it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 1266.68it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 1277.61it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 1276.01it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 1286.92it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 1284.79it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 1294.35it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 1292.62it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 1303.36it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 1301.74it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 1312.45it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 1310.85it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 1319.71it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 1317.96it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/103 [00:00<00:00, 1328.45it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/103 [00:00<00:00, 1326.83it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 1336.53it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 1334.87it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 1344.77it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 1338.24it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 1346.59it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 1343.84it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 1351.34it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 1348.60it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 1357.55it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 1354.95it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 1363.88it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 1359.55it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1368.55it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1366.03it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1361.52it/s, Materializing param=pooler.dense.weight]\n",
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "  [Query] Processing: List me all national parks sorted by their highest...\n",
            "[*] Step 1: í…ìŠ¤íŠ¸ ì •ì œ ë° êµ¬ì¡° ë¶„ì„ ì¤‘...\n",
            "[*] ì•Œë¦¼: ë‹¨ì¼ ì„¹ì…˜ ê°ì§€. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ 7ê°œ ë‹¨ìœ„ë¡œ ê°•ì œ ë¶„í• í•©ë‹ˆë‹¤.\n",
            "[*] Step 2: ë³‘ë ¬ ì „ì²˜ë¦¬ ê°€ë™ (ë‹¨ìœ„: 8 ì„¹ì…˜ / Workers: 7)\n",
            "\n",
            "Processing:   0%|          | 0/8 [00:00<?, ?it/s]\n",
            "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 225.59it/s]\n",
            "[*] Step 3: ì™„ë£Œ (ìƒì„±ëœ ì²­í¬ ìˆ˜: 30)\n",
            "[*] ì¸ë² ë”© ìƒì„± ì¤‘: 30 ì²­í¬ ë¶„ì„...\n",
            "[*] CPU ë©€í‹°í”„ë¡œì„¸ìŠ¤ ê°€ì† ëª¨ë“œ ê°€ë™ (Workers: 7)\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "1. **í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜**:\n",
            "   - \"national parks\"\n",
            "   - \"highest...\n",
            "[*] 30ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/30 [00:00<?, ?it/s]\n",
            "Scouting:   3%|â–         | 1/30 [00:00<00:25,  1.14it/s]\n",
            "Scouting:   7%|â–‹         | 2/30 [00:01<00:12,  2.21it/s]\n",
            "Scouting:  17%|â–ˆâ–‹        | 5/30 [00:01<00:03,  6.37it/s]\n",
            "Scouting:  23%|â–ˆâ–ˆâ–       | 7/30 [00:01<00:03,  6.85it/s]\n",
            "Scouting:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:01<00:03,  6.76it/s]\n",
            "Scouting:  33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [00:01<00:03,  5.87it/s]\n",
            "Scouting:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:02<00:02,  7.94it/s]\n",
            "Scouting:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 16/30 [00:02<00:01, 10.90it/s]\n",
            "Scouting:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:02<00:00, 12.03it/s]\n",
            "Scouting:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:02<00:00, 13.41it/s]\n",
            "Scouting:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 22/30 [00:02<00:00, 13.24it/s]\n",
            "Scouting:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:03<00:00,  7.14it/s]\n",
            "Scouting:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:03<00:00,  5.52it/s]\n",
            "Scouting:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:03<00:00,  5.94it/s]\n",
            "Scouting:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [00:04<00:00,  4.72it/s]\n",
            "Scouting:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:05<00:00,  3.14it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.83it/s]\n",
            "  [Query] Processing: List me all national parks where I can see brown b...\n",
            "[*] ë¡œì»¬ ìºì‹œ ë°œê²¬: data/cache/nationalparks_europe_txt_v2.pkl ë¡œë“œ ì¤‘...\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "1. **í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜**:\n",
            "   - \"brown bears\"\n",
            "   - \"national p...\n",
            "[*] 30ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/30 [00:00<?, ?it/s]\n",
            "Scouting:   3%|â–         | 1/30 [00:00<00:19,  1.51it/s]\n",
            "Scouting:   7%|â–‹         | 2/30 [00:00<00:10,  2.72it/s]\n",
            "Scouting:  10%|â–ˆ         | 3/30 [00:00<00:07,  3.82it/s]\n",
            "Scouting:  20%|â–ˆâ–ˆ        | 6/30 [00:01<00:03,  7.80it/s]\n",
            "Scouting:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:01<00:02,  7.94it/s]\n",
            "Scouting:  33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [00:01<00:02,  8.56it/s]\n",
            "Scouting:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:01<00:02,  7.52it/s]\n",
            "Scouting:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/30 [00:01<00:01,  9.39it/s]\n",
            "Scouting:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:02<00:01, 10.94it/s]\n",
            "Scouting:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:02<00:01,  9.24it/s]\n",
            "Scouting:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 19/30 [00:02<00:00, 11.04it/s]\n",
            "Scouting:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:02<00:00, 10.10it/s]\n",
            "Scouting:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:02<00:00,  9.66it/s]\n",
            "Scouting:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:03<00:00, 10.49it/s]\n",
            "Scouting:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [00:03<00:00, 10.71it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:03<00:00,  6.98it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:03<00:00,  7.81it/s]\n",
            "  [Query] Processing: Give me a table of all the national parks in scand...\n",
            "[*] ë¡œì»¬ ìºì‹œ ë°œê²¬: data/cache/nationalparks_europe_txt_v2.pkl ë¡œë“œ ì¤‘...\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "**1. í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜:**\n",
            "   - \"Scandinavian national parks\"\n",
            "...\n",
            "[*] 30ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/30 [00:00<?, ?it/s]\n",
            "Scouting:   3%|â–         | 1/30 [00:00<00:21,  1.33it/s]\n",
            "Scouting:  17%|â–ˆâ–‹        | 5/30 [00:01<00:04,  6.06it/s]\n",
            "Scouting:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:01<00:02,  9.70it/s]\n",
            "Scouting:  33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [00:01<00:01, 11.48it/s]\n",
            "Scouting:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:01<00:02,  6.70it/s]\n",
            "Scouting:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:02<00:02,  7.27it/s]\n",
            "Scouting:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:02<00:01, 11.15it/s]\n",
            "Scouting:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 22/30 [00:02<00:00, 13.01it/s]\n",
            "Scouting:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:02<00:00, 10.27it/s]\n",
            "Scouting:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:02<00:00,  9.65it/s]\n",
            "Scouting:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [00:03<00:00,  5.77it/s]\n",
            "Scouting:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:04<00:00,  3.88it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  4.05it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.47it/s]\n",
            "\n",
            "[Experiment] Starting: AI Act + Top generative use case\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 22310.13it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 5660.33it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 4485.89it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 748.72it/s, Materializing param=embeddings.LayerNorm.weight] \n",
            "Loading weights:   3%|â–         | 3/103 [00:00<00:00, 1016.06it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|â–         | 3/103 [00:00<00:00, 977.01it/s, Materializing param=embeddings.position_embeddings.weight] \n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 873.04it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 850.73it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 1011.50it/s, Materializing param=embeddings.word_embeddings.weight]     \n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 990.76it/s, Materializing param=embeddings.word_embeddings.weight] \n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 1113.14it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 893.45it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias] \n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 800.16it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 714.90it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 715.66it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 703.42it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 746.89it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 727.84it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 694.56it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 665.21it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 717.91it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 712.73it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 762.51it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 757.29it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|â–ˆâ–        | 13/103 [00:00<00:00, 801.23it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|â–ˆâ–        | 13/103 [00:00<00:00, 752.69it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|â–ˆâ–        | 14/103 [00:00<00:00, 729.96it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|â–ˆâ–        | 14/103 [00:00<00:00, 707.50it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 740.26it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 709.82it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 741.02it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 647.04it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 677.70it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 670.30it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 646.20it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 596.93it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 618.56it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 588.88it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 610.25it/s, Materializing param=encoder.layer.0.output.dense.bias]      \n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 592.55it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 604.57it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 602.11it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 624.51it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 600.39it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 620.77it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 586.88it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  23%|â–ˆâ–ˆâ–       | 24/103 [00:00<00:00, 607.57it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–       | 24/103 [00:00<00:00, 605.38it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 626.48it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 624.70it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 643.48it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 630.42it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 640.02it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 634.29it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 652.95it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 650.43it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 669.54it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 667.23it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 685.42it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 683.05it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 701.49it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 699.17it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 717.13it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 714.68it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 732.57it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 730.19it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–      | 34/103 [00:00<00:00, 748.20it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–      | 34/103 [00:00<00:00, 746.42it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 762.40it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 760.80it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 779.47it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 777.85it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 796.39it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 792.25it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 809.11it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 806.56it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 823.29it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 820.61it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 836.41it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 833.55it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 849.85it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 847.32it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 863.03it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 860.40it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 876.17it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 873.60it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/103 [00:00<00:00, 889.43it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/103 [00:00<00:00, 886.40it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/103 [00:00<00:00, 901.94it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 45/103 [00:00<00:00, 899.13it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 913.93it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 910.75it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 925.08it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 922.15it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 936.96it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 934.30it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 948.72it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 946.88it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 962.68it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 960.93it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 976.72it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 975.11it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 990.96it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 988.87it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 1004.36it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 1002.69it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 1017.99it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 1016.27it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/103 [00:00<00:00, 1031.51it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 55/103 [00:00<00:00, 1029.80it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 1041.48it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 1038.46it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 1051.85it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 1048.95it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 1061.65it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 1058.70it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 1071.65it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 1068.76it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 1081.90it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 1078.45it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 1091.17it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 1088.15it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1101.03it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1098.19it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1110.14it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1107.25it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1119.63it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1116.74it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/103 [00:00<00:00, 1128.78it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 65/103 [00:00<00:00, 1125.87it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1138.03it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1135.03it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 1147.31it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 1144.09it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 1156.04it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 1153.01it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 1164.95it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 1162.12it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 1173.55it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 1170.61it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 1182.17it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 1179.08it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 1190.45it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 1187.03it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 1198.51it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 1195.24it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 1206.48it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 1203.58it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/103 [00:00<00:00, 1210.04it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 75/103 [00:00<00:00, 1207.04it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 1218.10it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 1214.61it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 1225.44it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 1223.36it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 1235.34it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 1233.54it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 1245.76it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 1244.00it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 1255.43it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 1253.62it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 1265.56it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 1263.77it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 1275.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 1274.17it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 1283.04it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 1280.17it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 1290.32it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 1287.43it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 85/103 [00:00<00:00, 1297.50it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 85/103 [00:00<00:00, 1294.04it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/103 [00:00<00:00, 1303.99it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 86/103 [00:00<00:00, 1301.05it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 1310.77it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 1307.85it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 1317.19it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 1314.06it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 1323.89it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 1320.99it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 1329.14it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 1325.80it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 1335.03it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 1332.05it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 1341.12it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 1338.05it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 1347.29it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 1344.36it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 1353.86it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 1350.51it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 1359.77it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 1356.75it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/103 [00:00<00:00, 1366.09it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 96/103 [00:00<00:00, 1363.27it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 1368.84it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 1365.89it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 1374.80it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 1371.80it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 1380.32it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 1377.47it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 1387.18it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 1385.40it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 1395.76it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 1394.06it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 1403.76it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 1402.08it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1412.57it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1410.88it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 1407.04it/s, Materializing param=pooler.dense.weight]\n",
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "  [Query] Processing: Given a virtual ai assistant in the healthcare dom...\n",
            "[*] Step 1: í…ìŠ¤íŠ¸ ì •ì œ ë° êµ¬ì¡° ë¶„ì„ ì¤‘...\n",
            "[*] ì•Œë¦¼: ë‹¨ì¼ ì„¹ì…˜ ê°ì§€. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ 7ê°œ ë‹¨ìœ„ë¡œ ê°•ì œ ë¶„í• í•©ë‹ˆë‹¤.\n",
            "[*] Step 2: ë³‘ë ¬ ì „ì²˜ë¦¬ ê°€ë™ (ë‹¨ìœ„: 8 ì„¹ì…˜ / Workers: 7)\n",
            "\n",
            "Processing:   0%|          | 0/8 [00:00<?, ?it/s]\n",
            "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 346.32it/s]\n",
            "[*] Step 3: ì™„ë£Œ (ìƒì„±ëœ ì²­í¬ ìˆ˜: 22)\n",
            "[*] ì¸ë² ë”© ìƒì„± ì¤‘: 22 ì²­í¬ ë¶„ì„...\n",
            "[*] CPU ë©€í‹°í”„ë¡œì„¸ìŠ¤ ê°€ì† ëª¨ë“œ ê°€ë™ (Workers: 7)\n",
            "[*] íƒìƒ‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: ### STRATEGIC SEARCH PLAN\n",
            "\n",
            "#### 1. **í•µì‹¬ í‚¤ì›Œë“œ ì •ì˜**\n",
            "   - **ì£¼ìš” í‚¤ì›Œë“œ**:\n",
            "     - \"ê°€ìƒ AI ...\n",
            "[*] 22ê°œ ìœ„ì¹˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ìŠ¤ì¹´ìš°íŒ… ê°œì‹œ...\n",
            "\n",
            "Scouting:   0%|          | 0/22 [00:00<?, ?it/s]\n",
            "Scouting:   5%|â–         | 1/22 [00:01<00:22,  1.06s/it]\n",
            "Scouting:  14%|â–ˆâ–        | 3/22 [00:01<00:10,  1.75it/s]\n",
            "Scouting:  23%|â–ˆâ–ˆâ–       | 5/22 [00:02<00:05,  2.87it/s]\n",
            "Scouting:  27%|â–ˆâ–ˆâ–‹       | 6/22 [00:02<00:04,  3.36it/s]\n",
            "Scouting:  32%|â–ˆâ–ˆâ–ˆâ–      | 7/22 [00:02<00:03,  3.92it/s]\n",
            "Scouting:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 8/22 [00:02<00:03,  4.04it/s]\n",
            "Scouting:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 11/22 [00:02<00:01,  6.56it/s]\n",
            "Scouting:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12/22 [00:03<00:01,  6.06it/s]\n",
            "Scouting:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 13/22 [00:03<00:01,  5.46it/s]\n",
            "Scouting:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 16/22 [00:03<00:01,  5.81it/s]\n",
            "Scouting:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 19/22 [00:03<00:00,  8.34it/s]\n",
            "Scouting:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 21/22 [00:04<00:00,  5.74it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  1.71it/s]\n",
            "Scouting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.05it/s]\n",
            "\n",
            "=== All experiments completed. Check the results folder. ===\n",
            "/home/remote/jwoo/.local/share/uv/python/cpython-3.10-linux-x86_64-gnu/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 16 leaked semaphore objects to clean up at shutdown\n",
            "  warnings.warn('resource_tracker: There appear to be %d '\n",
            "\n",
            "âœ… ì‹¤í—˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "def run_experiment_script():\n",
        "    # í˜„ì¬ í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
        "    env = os.environ.copy()\n",
        "    # PYTHONPATHì— í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬(í”„ë¡œì íŠ¸ ë£¨íŠ¸) ì¶”ê°€\n",
        "    env[\"PYTHONPATH\"] = os.getcwd()\n",
        "    \n",
        "    # íŒŒì´ì¬ ì‹¤í–‰ ê²½ë¡œ ì„¤ì •\n",
        "    cmd = [\"python\", \"src/main.py\"]\n",
        "    \n",
        "    print(\"ğŸš€ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ (PYTHONPATH ì„¤ì • ì™„ë£Œ)...\\n\")\n",
        "    \n",
        "    # í”„ë¡œì„¸ìŠ¤ ì‹œì‘\n",
        "    process = subprocess.Popen(\n",
        "        cmd, \n",
        "        stdout=subprocess.PIPE, \n",
        "        stderr=subprocess.STDOUT, \n",
        "        text=True, \n",
        "        encoding='utf-8',\n",
        "        env=env # ìˆ˜ì •ëœ í™˜ê²½ ë³€ìˆ˜ ì „ë‹¬\n",
        "    )\n",
        "\n",
        "    # ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥\n",
        "    if process.stdout:\n",
        "        for line in iter(process.stdout.readline, \"\"):\n",
        "            print(line, end=\"\")\n",
        "    \n",
        "    process.wait()\n",
        "    \n",
        "    if process.returncode == 0:\n",
        "        print(\"\\nâœ… ì‹¤í—˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        print(f\"\\nâŒ ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (Return Code: {process.returncode})\")\n",
        "\n",
        "# ì‹¤í—˜ ì‹¤í–‰\n",
        "run_experiment_script()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## ğŸ“Š Experiment Summary"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2026-02-11 10:12:23</th>\n",
              "      <th>VMware Documentation</th>\n",
              "      <th>List the differences of the 3q, 3s and 3m release in a table.</th>\n",
              "      <th>The differences between ESXi 7.0 Update 3q, 3s, and 3m releases are as follows:  | Feature/Component | ESXi 7.0 Update 3q | ESXi 7.0 Update 3s | ESXi 7.0 Update 3m | |------------------|------------------|------------------|------------------| | **Release Date** | Not specified | Not specified | May 03, 2023 | | **Build Number** | Not specified | Not specified | 21686933 | | **Category** | Not specified | Not specified | Bugfix | | **Key Fixes** | Not specified | Not specified | - PR 3164897: After an upgrade to ESXi 7.0 Update 3l, some ESXi hosts and their VMs might lose network connectivity due to an unexpected change in the NIC teaming policy. &lt;br&gt; - PR 3182870: After upgrading the ntg3 driver to version 4.1.9.0-4vmw, Broadcom NICs with fiber physical connectivity might lose network. | | **Affected Components** | Not specified | Not specified | - ESXi Component - core ESXi VIBs &lt;br&gt; - ESXi Install/Upgrade Component &lt;br&gt; - Broadcom NetXtreme I ESX VMKAPI ethernet driver | | **PRs Fixed** | Not specified | Not specified | 3164897, 3182870 | | **CVE Numbers** | Not specified | Not specified | N/A | | **ntg3 Driver Version** | Not specified | Not specified | 4.1.9.0-5vmw | | **Additional Notes** | Not specified | Not specified | - The fix adds a module parameter, fifoElastic, which can be enabled in case of jumbo frame drops in certain Dell switches. |  ### Summary: - **ESXi 7.0 Update 3m** is the only release with detailed information provided, including specific bug fixes, affected components, and the ntg3 driver version. - **ESXi 7.0 Update 3q and 3s** do not have detailed information in the provided evidence, making it difficult to compare them directly with 3m.  For a comprehensive comparison, more detailed information about ESXi 7.0 Update 3q and 3s would be required.</th>\n",
              "      <th>185.43s</th>\n",
              "      <th>vmware.txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2026-02-11 10:12:43</td>\n",
              "      <td>VMware Documentation</td>\n",
              "      <td>List me a timeline for when each version of th...</td>\n",
              "      <td>Here is a timeline of major VMware vCenter Ser...</td>\n",
              "      <td>20.16s</td>\n",
              "      <td>vmware.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2026-02-11 10:12:56</td>\n",
              "      <td>EU AI Act Analysis</td>\n",
              "      <td>How many articles are there in the AI Act?</td>\n",
              "      <td>The AI Act contains **83 articles** in total. ...</td>\n",
              "      <td>10.42s</td>\n",
              "      <td>aiact.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2026-02-11 10:13:16</td>\n",
              "      <td>EU AI Act Analysis</td>\n",
              "      <td>Summarize the requirements for high-risk AI sy...</td>\n",
              "      <td>### **Summary of Requirements for High-Risk AI...</td>\n",
              "      <td>20.07s</td>\n",
              "      <td>aiact.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2026-02-11 10:13:28</td>\n",
              "      <td>EU AI Act Analysis</td>\n",
              "      <td>What are the prohibited AI practices according...</td>\n",
              "      <td>The prohibited AI practices according to Artic...</td>\n",
              "      <td>11.79s</td>\n",
              "      <td>aiact.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2026-02-11 10:13:44</td>\n",
              "      <td>EU National Parks File</td>\n",
              "      <td>List me all national parks sorted by their hig...</td>\n",
              "      <td>Based on the extracted evidence, here is a lis...</td>\n",
              "      <td>14.05s</td>\n",
              "      <td>nationalparks_europe.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2026-02-11 10:13:55</td>\n",
              "      <td>EU National Parks File</td>\n",
              "      <td>List me all national parks where I can see bro...</td>\n",
              "      <td>Based on the extracted evidence, here are the ...</td>\n",
              "      <td>11.11s</td>\n",
              "      <td>nationalparks_europe.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2026-02-11 10:14:10</td>\n",
              "      <td>EU National Parks File</td>\n",
              "      <td>Give me a table of all the national parks in s...</td>\n",
              "      <td>Here is a table of the national parks in Scand...</td>\n",
              "      <td>14.31s</td>\n",
              "      <td>nationalparks_europe.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2026-02-11 10:14:39</td>\n",
              "      <td>AI Act + Top generative use case</td>\n",
              "      <td>Given a virtual ai assistant in the healthcare...</td>\n",
              "      <td>### **Noteworthy Articles in the AI Act for a ...</td>\n",
              "      <td>26.46s</td>\n",
              "      <td>aiact.txt, top_generative_use_cases.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   2026-02-11 10:12:23              VMware Documentation  \\\n",
              "0  2026-02-11 10:12:43              VMware Documentation   \n",
              "1  2026-02-11 10:12:56                EU AI Act Analysis   \n",
              "2  2026-02-11 10:13:16                EU AI Act Analysis   \n",
              "3  2026-02-11 10:13:28                EU AI Act Analysis   \n",
              "4  2026-02-11 10:13:44            EU National Parks File   \n",
              "5  2026-02-11 10:13:55            EU National Parks File   \n",
              "6  2026-02-11 10:14:10            EU National Parks File   \n",
              "7  2026-02-11 10:14:39  AI Act + Top generative use case   \n",
              "\n",
              "  List the differences of the 3q, 3s and 3m release in a table.  \\\n",
              "0  List me a timeline for when each version of th...              \n",
              "1         How many articles are there in the AI Act?              \n",
              "2  Summarize the requirements for high-risk AI sy...              \n",
              "3  What are the prohibited AI practices according...              \n",
              "4  List me all national parks sorted by their hig...              \n",
              "5  List me all national parks where I can see bro...              \n",
              "6  Give me a table of all the national parks in s...              \n",
              "7  Given a virtual ai assistant in the healthcare...              \n",
              "\n",
              "  The differences between ESXi 7.0 Update 3q, 3s, and 3m releases are as follows:  | Feature/Component | ESXi 7.0 Update 3q | ESXi 7.0 Update 3s | ESXi 7.0 Update 3m | |------------------|------------------|------------------|------------------| | **Release Date** | Not specified | Not specified | May 03, 2023 | | **Build Number** | Not specified | Not specified | 21686933 | | **Category** | Not specified | Not specified | Bugfix | | **Key Fixes** | Not specified | Not specified | - PR 3164897: After an upgrade to ESXi 7.0 Update 3l, some ESXi hosts and their VMs might lose network connectivity due to an unexpected change in the NIC teaming policy. <br> - PR 3182870: After upgrading the ntg3 driver to version 4.1.9.0-4vmw, Broadcom NICs with fiber physical connectivity might lose network. | | **Affected Components** | Not specified | Not specified | - ESXi Component - core ESXi VIBs <br> - ESXi Install/Upgrade Component <br> - Broadcom NetXtreme I ESX VMKAPI ethernet driver | | **PRs Fixed** | Not specified | Not specified | 3164897, 3182870 | | **CVE Numbers** | Not specified | Not specified | N/A | | **ntg3 Driver Version** | Not specified | Not specified | 4.1.9.0-5vmw | | **Additional Notes** | Not specified | Not specified | - The fix adds a module parameter, fifoElastic, which can be enabled in case of jumbo frame drops in certain Dell switches. |  ### Summary: - **ESXi 7.0 Update 3m** is the only release with detailed information provided, including specific bug fixes, affected components, and the ntg3 driver version. - **ESXi 7.0 Update 3q and 3s** do not have detailed information in the provided evidence, making it difficult to compare them directly with 3m.  For a comprehensive comparison, more detailed information about ESXi 7.0 Update 3q and 3s would be required.  \\\n",
              "0  Here is a timeline of major VMware vCenter Ser...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "1  The AI Act contains **83 articles** in total. ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "2  ### **Summary of Requirements for High-Risk AI...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "3  The prohibited AI practices according to Artic...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "4  Based on the extracted evidence, here is a lis...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "5  Based on the extracted evidence, here are the ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "6  Here is a table of the national parks in Scand...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "7  ### **Noteworthy Articles in the AI Act for a ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "\n",
              "  185.43s                               vmware.txt  \n",
              "0  20.16s                               vmware.txt  \n",
              "1  10.42s                                aiact.txt  \n",
              "2  20.07s                                aiact.txt  \n",
              "3  11.79s                                aiact.txt  \n",
              "4  14.05s                 nationalparks_europe.txt  \n",
              "5  11.11s                 nationalparks_europe.txt  \n",
              "6  14.31s                 nationalparks_europe.txt  \n",
              "7  26.46s  aiact.txt, top_generative_use_cases.txt  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if os.path.exists(log_path):\n",
        "    # CSV ë¡œë“œ (utf-8-sig ì¸ì½”ë”© ì ìš©)\n",
        "    df = pd.read_csv(log_path)\n",
        "    \n",
        "    display(Markdown(\"## ğŸ“Š Experiment Summary\"))\n",
        "    \n",
        "    # ê¸°ë³¸ í†µê³„ ë° í…Œì´ë¸” ì¶œë ¥\n",
        "    display(df.tail(10)) # ìµœê·¼ ì‹¤í–‰ ê²°ê³¼ 10ê±´\n",
        "    \n",
        "    # ì‹¤í—˜ë³„ í‰ê·  ì†Œìš” ì‹œê°„ ê³„ì‚°\n",
        "    if 'latency' in df.columns:\n",
        "        avg_latency = df.groupby('experiment_name')['latency'].apply(\n",
        "            lambda x: x.str.replace('s', '').astype(float).mean()\n",
        "        )\n",
        "        display(Markdown(\"### ğŸ•’ Experiment Inference Time (Latency)\"))\n",
        "        print(avg_latency)\n",
        "else:\n",
        "    print(\"âš ï¸ ê²°ê³¼ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹¤í—˜ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'experiment_name'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/THU/Capstone/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'experiment_name'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(log_path)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m----> 4\u001b[0m     latest_exp \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperiment_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### ğŸ” Experiment Output: **\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_exp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      7\u001b[0m     subset \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m latest_exp]\n",
            "File \u001b[0;32m~/THU/Capstone/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/THU/Capstone/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'experiment_name'"
          ]
        }
      ],
      "source": [
        "if os.path.exists(log_path):\n",
        "    df = pd.read_csv(log_path)\n",
        "    if not df.empty:\n",
        "        latest_exp = df['experiment_name'].iloc[0]\n",
        "        display(Markdown(f\"### ğŸ” Experiment Output: **{latest_exp}**\"))\n",
        "        \n",
        "        subset = df[df['experiment_name'] == latest_exp]\n",
        "        for _, row in subset.iterrows():\n",
        "            display(Markdown(f\"---\"))\n",
        "            display(Markdown(f\"**Query:** {row['query']}\"))\n",
        "            display(Markdown(f\"**Answer:** {row['answer']}\"))\n",
        "            display(Markdown(f\"*InferTime: {row.get('latency', 'N/A')} | Source: {row.get('source_files', 'N/A')}*\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Capstone (3.10.19)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
